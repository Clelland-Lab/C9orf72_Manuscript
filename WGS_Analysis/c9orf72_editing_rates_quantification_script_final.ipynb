{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad3231-ae4f-41c5-95e5-f98c8b6a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.instance().run_line_magic('reset', '-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa69455c-ddbb-4f48-b3e4-44f9a8a61b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pysam\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "strandedness = []\n",
    "fasta = pysam.FastaFile(\"hg38.fa\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f9f43-7f3a-41bb-ae43-75626f27f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "from pathlib import Path\n",
    "\n",
    "#contains the locations of all the guides\n",
    "altc = 'altc_circle_seq_3_output.bed'\n",
    "alt7 = 'alt7_circle_seq_3_output.bed'\n",
    "rex4 = 'rex4_circle_seq_3_output.bed'\n",
    "rexc = 'rexc_circle_seq_3_output.bed'\n",
    "\n",
    "#all the dfs (at the moment) \n",
    "\n",
    "# ALT7\n",
    "ALT7_1_BAMs = Path('HG38_NEW') / 'ALT7_HG38_NEW_FILTER_MPQ20' / 'rep1'\n",
    "ALT7_2_BAMs = Path('HG38_NEW') / 'ALT7_HG38_NEW_FILTER_MPQ20' / 'rep2' \n",
    "\n",
    "# ALTC\n",
    "ALTC_1_BAMs = Path('HG38_NEW') / 'ALTC_HG38_NEW_FILTER_MPQ20' / 'rep1'\n",
    "ALTC_2_BAMs = Path('HG38_NEW') / 'ALTC_HG38_NEW_FILTER_MPQ20' / 'rep2'\n",
    "\n",
    "# REXC\n",
    "REXC_1_BAMs = Path('HG38_NEW') / 'REXC_HG38_NEW_FILTER_MPQ20' / 'rep1'\n",
    "REXC_2_BAMs = Path('HG38_NEW') / 'REXC_HG38_NEW_FILTER_MPQ20' / 'rep2'\n",
    "\n",
    "# REX4\n",
    "REX4_2_BAMs = Path('HG38_NEW') / 'REX4_HG38_NEW_FILTER_MPQ20' / 'rep1'\n",
    "REX4_3_BAMs = Path('HG38_NEW') / 'REX4_HG38_NEW_FILTER_MPQ20' / 'rep2'\n",
    "\n",
    "\n",
    "#This is the no nucleoinfection BAM\n",
    "ALTC_NO_NUNC = Path('HG38_NEW') / 'ALTC_HG38_NEW_FILTER_MPQ20' / 'nunc'\n",
    "REX4_NO_NUNC = Path('HG38_NEW') / 'REX4_HG38_NEW_FILTER_MPQ20' / 'nunc'\n",
    "ALT7_NO_NUNC = Path('HG38_NEW') / 'ALT7_HG38_NEW_FILTER_MPQ20' / 'nunc'\n",
    "REXC_NO_NUNC = Path('HG38_NEW') / 'REXC_HG38_NEW_FILTER_MPQ20' / 'nunc'\n",
    "\n",
    "def read_bam_files_to_dict(directory):\n",
    "    bam_files_dict = {}\n",
    "    \n",
    "    #sort the directory by name\n",
    "    sorted_bam_files = sorted(directory.glob('*.bam'), key=lambda f: f.name)\n",
    "    \n",
    "    for bam_file in sorted_bam_files:  # Filter for .bam files\n",
    "        #bam = pysam.AlignmentFile(bam_file, \"rb\") \n",
    "        bam_files_dict[bam_file.name] = bam_file.resolve() # Store filename as key, BAM object as value\n",
    "    return bam_files_dict\n",
    "\n",
    "# Read BAM files from each directory\n",
    "\n",
    "#ALTC\n",
    "bam_files_AltC_1 = read_bam_files_to_dict(ALTC_1_BAMs)\n",
    "bam_files_AltC_2 = read_bam_files_to_dict(ALTC_2_BAMs)\n",
    "\n",
    "#ALT7\n",
    "bam_files_Alt7_1 = read_bam_files_to_dict(ALT7_1_BAMs)\n",
    "bam_files_Alt7_2 = read_bam_files_to_dict(ALT7_2_BAMs)\n",
    "\n",
    "#REX4\n",
    "bam_files_REX4_2 = read_bam_files_to_dict(REX4_2_BAMs)\n",
    "bam_files_REX4_3 = read_bam_files_to_dict(REX4_3_BAMs)\n",
    "\n",
    "#REXC\n",
    "bam_files_REXC_1 = read_bam_files_to_dict(REXC_1_BAMs)\n",
    "bam_files_REXC_2 = read_bam_files_to_dict(REXC_2_BAMs)\n",
    "\n",
    "#NO_NUNC \n",
    "bam_files_NO_NUNC_ALTC = read_bam_files_to_dict(ALTC_NO_NUNC)\n",
    "bam_files_NO_NUNC_ALT7 = read_bam_files_to_dict(ALT7_NO_NUNC)\n",
    "bam_files_NO_NUNC_REX4 = read_bam_files_to_dict(REX4_NO_NUNC)\n",
    "bam_files_NO_NUNC_REXC = read_bam_files_to_dict(REXC_NO_NUNC)\n",
    "\n",
    "\n",
    "#THE BAM FILES TO CONSIDER\n",
    "all_bams = {'ALTC': [bam_files_AltC_1, bam_files_AltC_2],\n",
    "            'ALT7': [bam_files_Alt7_1, bam_files_Alt7_2],\n",
    "            'REX4': [bam_files_REX4_2, bam_files_REX4_3],\n",
    "            'REXC': [bam_files_REXC_1, bam_files_REXC_2]}\n",
    "\n",
    "#THE CONTROL BAMS\n",
    "all_controls = {'ALTC':bam_files_NO_NUNC_ALTC,\n",
    "                'ALT7':bam_files_NO_NUNC_ALT7,\n",
    "                'REX4':bam_files_NO_NUNC_REX4,\n",
    "                'REXC':bam_files_NO_NUNC_REXC}\n",
    "\n",
    "#TSVs for the locations of the potential locations\n",
    "all_tsvs = {'ALTC':pd.read_csv(altc, sep='\\t',  names=['chrom','start','end','name','na','na2','REGION'])[:],\n",
    "                'ALT7':pd.read_csv(alt7, sep='\\t',  names=['chrom','start','end','na','na2','REGION'])[:],\n",
    "                'REX4':pd.read_csv(rex4, sep='\\t',  names=['chrom','start','end','na','na2','REGION'])[:],\n",
    "                'REXC':pd.read_csv(rexc, sep='\\t',  names=['chrom','start','end','na','na2','REGION'])[:]}\n",
    "\n",
    "#iterate through all the tsvs and make a \"REGION' entry\n",
    "for condition in all_tsvs:\n",
    "    all_tsvs[condition]['REGION'] = ['REGION_' + str(i) + '.bam' for i in np.arange(0,  all_tsvs[condition]['REGION'].shape[0])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d421ebf-78ae-45b8-9717-c21c146f364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_read = None\n",
    "\n",
    "def find_deletion_locs(inbam, chrom, start_loc, end_loc,strand):\n",
    "    deletions = []\n",
    "    insertions = []\n",
    "    indels = []\n",
    "    count = 0\n",
    "    \n",
    "    for read in inbam.fetch(chrom, start_loc, end_loc):\n",
    "        deletion_lst = []\n",
    "        insertion_lst = []\n",
    "        indel_lst = []\n",
    "\n",
    "        count += 1\n",
    "        ref_start = read.reference_start  # Correct attribute for reference start position\n",
    "\n",
    "        if read.is_unmapped:\n",
    "            break\n",
    "        if read.cigartuples[0][0] == 4:\n",
    "            ref_start = ref_start - read.cigartuples[0][1] \n",
    "        \n",
    "        cigar = read.cigartuples\n",
    "    \n",
    "        #the bases traversed - where we are in the read \n",
    "        l_read = 0\n",
    "        \n",
    "        #the exact start position of the read - where we are in the reference \n",
    "        l = ref_start\n",
    "        segment_index = 0\n",
    "\n",
    "        #go through now the entire cigar array\n",
    "        for op, length in cigar:\n",
    "\n",
    "            if strand == '-':\n",
    "                if length + l > start_loc and l < start_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                elif l + length > end_loc and l < end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                elif l >= start_loc and l <= end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                elif l + length >= start_loc and l + length  <= end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "\n",
    "            if strand == '+' or strand == 'unknown':\n",
    "                if length + l > end_loc and l < end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                elif length + l > start_loc and l < start_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                elif l >= start_loc and l  <= end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                elif l + length >= start_loc and l + length  <= end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "            if l + length < end_loc and l + length > start_loc :\n",
    "                if op == 1:\n",
    "                    insertion_lst.append([\"insertions\", length, (l, l+length)])\n",
    "                    indel_lst.append([\"indels\", length])\n",
    "                    \n",
    "            #insertion begins in the guide loc\n",
    "            if l  < end_loc and l > start_loc :\n",
    "                if op == 1:\n",
    "                    insertion_lst.append([\"insertions\", length, (l, l+length)])\n",
    "                    indel_lst.append([\"indels\", length])\n",
    "                \n",
    "            '''below traverses the region of the read we are considering'''\n",
    "            if op == 0:  \n",
    "                l_read += length\n",
    "                l += length\n",
    "            elif op == 1:  \n",
    "                l_read += length\n",
    "                \n",
    "            elif op == 2: \n",
    "                l += length \n",
    "                \n",
    "            elif op == 3:  \n",
    "                l += length \n",
    "                \n",
    "            elif op == 4:  \n",
    "                l_read += length\n",
    "                l += length \n",
    "                \n",
    "            elif op == 5: \n",
    "                pass\n",
    "            elif op == 6: \n",
    "                pass\n",
    "            elif op == 7:  \n",
    "                l_read += length\n",
    "                l += length\n",
    "                \n",
    "            elif op == 8: \n",
    "                l_read += length\n",
    "                l += length\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown CIGAR operation code {op}\")\n",
    "\n",
    "            if l > end_loc:\n",
    "                if len(deletion_lst) > 0:\n",
    "                    deletions.append(deletion_lst)\n",
    "                if len(insertion_lst) > 0:\n",
    "                    insertions.append(insertion_lst)\n",
    "                if len(indel_lst) > 0:\n",
    "                    indels.append(indel_lst)\n",
    "                break\n",
    "                \n",
    "            segment_index += 1\n",
    "            \n",
    "    return deletions, insertions, indels\n",
    "    inbam.close()\n",
    "\n",
    "\n",
    "def construct_df(locations, bams, del_lst, ins_lst, indel_lst):\n",
    "    locations = locations.copy()    \n",
    "    count = 0\n",
    "    for region in bams:\n",
    "        if count % 1000 == 0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "            \n",
    "        inbam = bams[region]\n",
    "        inbam = pysam.AlignmentFile(inbam, \"rb\")  # Store filename as key, BAM object as value\n",
    "\n",
    "        chrom = locations[locations['REGION'] == region]['chrom'].tolist()[0]\n",
    "        start = locations[locations['REGION'] == region]['start'].tolist()[0]\n",
    "        end = locations[locations['REGION'] == region]['end'].tolist()[0]\n",
    "\n",
    "        deletions = del_lst[region]\n",
    "        indels = indel_lst[region]\n",
    "        \n",
    "        deletion_lengths = [\n",
    "            [deletion[1] for deletion in read if 'deletions' in deletion[0]]\n",
    "            for read in deletions\n",
    "        ]\n",
    "\n",
    "        deletion_coords = [\n",
    "            [deletion[2] for deletion in read if 'deletions' in deletion[0]]\n",
    "            for read in deletions\n",
    "        ]\n",
    "\n",
    "        indel_lengths = [\n",
    "            [indel[1] for indel in read if 'indel' in indel[0]]\n",
    "            for read in indels\n",
    "        ]\n",
    "        \n",
    "        num_deletions = len(deletion_lengths)\n",
    "        deletion_extending_past_region_lengths = [deletion[1] for read in deletions for deletion in read if 'extending' in deletion[0]]\n",
    "        deletion_extending_past_region_coords = [deletion[2] for read in deletions for deletion in read if 'extending' in deletion[0]]\n",
    "        num_deletions_extending_past_region = len(deletion_extending_past_region_coords)\n",
    "        \n",
    "        insertions = ins_lst[region]        \n",
    "        \n",
    "        insertion_lengths = [\n",
    "            [insertion[1] for insertion in read if 'insertions' in insertion[0]]\n",
    "            for read in insertions \n",
    "        ]\n",
    "        \n",
    "        insertion_coords = [\n",
    "            [insertion[2] for insertion in read if 'insertions' in insertion[0]]\n",
    "            for read in insertions\n",
    "        ]\n",
    "        \n",
    "        num_insertions = len(insertion_coords)\n",
    "        num_indels = len(indel_lengths)\n",
    "\n",
    "        total_reads = sum(1 for read in inbam.fetch(chrom, int(start), int(end)))\n",
    "        \n",
    "        locations.loc[locations['REGION'] == region, 'total_reads'] = total_reads\n",
    "        locations.loc[locations['REGION'] == region, 'forward_reads'] = sum(1 for read in inbam.fetch(chrom, int(start), int(end)) if not read.is_reverse)\n",
    "        locations.loc[locations['REGION'] == region, 'reverse_reads'] = sum(1 for read in inbam.fetch(chrom, int(start), int(end)) if read.is_reverse)\n",
    "                    \n",
    "        #collect info about all deletions\n",
    "        locations.loc[locations['REGION'] == region, 'deletion lengths'] = str(deletion_lengths)\n",
    "        locations.loc[locations['REGION'] == region, 'deletion coords'] = str(deletion_coords)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with deletion(s)'] = str(num_deletions)\n",
    "        #collect info about all insertions\n",
    "        locations.loc[locations['REGION'] == region, 'insertion lengths'] = str(insertion_lengths)\n",
    "        locations.loc[locations['REGION'] == region, 'insertion coords'] = str(insertion_coords)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with insertion(s)'] = str(num_insertions)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with indels'] = str(num_indels)     \n",
    "        #collect info about all deletions that go past the guide site\n",
    "        locations.loc[locations['REGION'] == region, 'deletion extending past region lengths'] = str(deletion_extending_past_region_lengths)\n",
    "        locations.loc[locations['REGION'] == region, 'deletion extending past region coords'] = str(deletion_extending_past_region_coords)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with deletion extending past region'] = str(num_deletions_extending_past_region)     \n",
    "\n",
    "        if total_reads != 0:\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an deletion'] = int(num_deletions) / int(total_reads)\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an insertion'] = int(num_insertions) / int(total_reads)\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an indel'] = int(num_indels) / int(total_reads)\n",
    "        else:\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an insertion'] = None\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an deletion'] = None\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an indel'] = None\n",
    "        #close the bam file\n",
    "        inbam.close()\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e165b86-5ce8-4c55-8c85-232fa8b0fdda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "import logging\n",
    "\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    all_tsvs[condition]['strandedness'] = 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e39e3-f550-4c9d-8da0-587030901ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_del_dict = {'ALTC':[{},{}],'ALT7':[{},{}],'REXC':[{},{}],'REX4':[{},{}]}\n",
    "all_ins_dict = {'ALTC':[{},{}],'ALT7':[{},{}],'REXC':[{},{}],'REX4':[{},{}]}\n",
    "all_ind_dict = {'ALTC':[{},{}],'ALT7':[{},{}],'REXC':[{},{}],'REX4':[{},{}]}\n",
    "\n",
    "#goes through all conditions, all bams and all replicates - extracts each region analyzed and populates dictionary\n",
    "for condition in ['REXC', 'REX4', 'ALTC', 'ALT7']:\n",
    "    condition_bams = all_bams[condition]\n",
    "    tsv = all_tsvs[condition]    \n",
    "    replicate_num = 0\n",
    "    for replicate in condition_bams:\n",
    "        count = 0       \n",
    "        for bam in replicate:\n",
    "            bam_basename = ''\n",
    "            \n",
    "            if count % 1000 == 0:\n",
    "                print(count)\n",
    "    \n",
    "            count += 1\n",
    "            chrom = tsv[tsv['REGION'] == bam]['chrom'].tolist()[0]\n",
    "            start = tsv[tsv['REGION'] == bam]['start'].tolist()[0]\n",
    "            end = tsv[tsv['REGION'] == bam]['end'].tolist()[0]\n",
    "            strand = 'unknown'\n",
    "            bam_file = pysam.AlignmentFile(replicate[bam], \"rb\") \n",
    "\n",
    "            all_del_dict[condition][replicate_num][bam],all_ins_dict[condition][replicate_num][bam], all_ind_dict[condition][replicate_num][bam] = find_deletion_locs(bam_file, chrom, int(start), int(end), strand)        \n",
    "            bam_file.close()  # Close the BAM file\n",
    "        replicate_num += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198cb5-b16d-4428-820f-02934155e5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_del_dict_wt = {'ALTC':{},'ALT7':{},'REXC':{},'REX4':{}}\n",
    "all_ins_dict_wt = {'ALTC':{},'ALT7':{},'REXC':{},'REX4':{}}\n",
    "all_ind_dict_wt = {'ALTC':{},'ALT7':{},'REXC':{},'REX4':{}}\n",
    "\n",
    "for condition in [\"ALTC\", \"REXC\", \"REX4\", \"ALT7\"]:\n",
    "    condition_bams = all_controls[condition]\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for bam in condition_bams:    \n",
    "        \n",
    "        if count % 1000 == 0:\n",
    "            print(condition)\n",
    "            print(count)\n",
    "                \n",
    "        count += 1\n",
    "\n",
    "        chrom = all_tsvs[condition][all_tsvs[condition]['REGION'] == bam]['chrom'].tolist()[0]\n",
    "        start = all_tsvs[condition][all_tsvs[condition]['REGION'] == bam]['start'].tolist()[0]\n",
    "        end = all_tsvs[condition][all_tsvs[condition]['REGION'] == bam]['end'].tolist()[0]\n",
    "                    \n",
    "        #open the bam_file\n",
    "        bam_file = pysam.AlignmentFile(all_controls[condition][bam], \"rb\") \n",
    "        \n",
    "        all_del_dict_wt[condition][bam],all_ins_dict_wt[condition][bam], all_ind_dict_wt[condition][bam] = find_deletion_locs(bam_file, chrom, int(start), int(end), strand)\n",
    "        bam_file.close()  # Close the BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4b73f-e33d-4377-991b-332b71f73533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edited_dfs = {'ALTC': [None, None],\n",
    "      'ALT7': [None, None],\n",
    "      'REXC': [None, None],\n",
    "      'REX4':[None, None]}\n",
    "\n",
    "control_dfs = {'ALTC': None,\n",
    "      'ALT7': None,\n",
    "      'REXC': None,\n",
    "      'REX4': None}\n",
    "\n",
    "#iterate through the conditions (ALTC, ALT7, REX4, and REXC) and then create tables\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in np.arange(0,2):\n",
    "        edited_dfs[condition][replicate] = construct_df(all_tsvs[condition],all_bams[condition][replicate], all_del_dict[condition][replicate],\n",
    "                     all_ins_dict[condition][replicate], all_ind_dict[condition][replicate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278b965-f9aa-475b-8515-46613197f630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    control_dfs[condition] = construct_df(all_tsvs[condition],all_controls[condition], all_del_dict_wt[condition],\n",
    "                 all_ins_dict_wt[condition], all_ind_dict_wt[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cc39e-42fe-485f-a520-520d3e03da9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in  np.arange(0,2):\n",
    "        df = edited_dfs[condition][replicate]\n",
    "        df.to_csv(str(condition) + 'consensus_indel_rates_hg38_new_con_filtered_mp20' + str(replicate) + '.csv', index=False) \n",
    "\n",
    "\n",
    "for condition in ['ALTC','ALT7', 'REXC', 'REX4']:\n",
    "    df = control_dfs[condition]\n",
    "    display(df)\n",
    "    df.to_csv(str(condition) + 'consensus_indel_rates_control_hg38_new_con_filtered_mp20' + '.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef2e4d-9fa8-4d0a-87bc-2863d06a165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def construct_comp_tbl(wt, edited):\n",
    "    comp_df = pd.DataFrame([])\n",
    "\n",
    "    # Ensure 'REGION' column is included\n",
    "    comp_df['REGION'] = wt['REGION'].tolist()\n",
    "\n",
    "    #construct a comparison table\n",
    "    for index, row in wt.iterrows():\n",
    "        cont = pd.DataFrame([])\n",
    "        cont_indel = pd.DataFrame([])\n",
    "        \n",
    "        region = row['REGION']\n",
    "        cont['wt'] = [int(row['number of reads with indels']),\n",
    "        int(row['total_reads']) - int(row['number of reads with indels'])]\n",
    "\n",
    "        row2 = edited.iloc[index]\n",
    "        cont['edited'] = [int(row2['number of reads with indels']),\n",
    "        int(row2['total_reads']) - int(row2['number of reads with indels'])]\n",
    "        \n",
    "        cont['type'] = ['indel', 'no indel']\n",
    "        cont.set_index('type', inplace=True)\n",
    "        odds_ratio, p_value = stats.fisher_exact(cont)\n",
    "        \n",
    "        comp_df.loc[comp_df['REGION'] == region, 'chrom'] = row['chrom']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'start'] = row2['start']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'end'] = row['end']\n",
    "        \n",
    "        comp_df.loc[comp_df['REGION'] == region, 'edited indel %'] = row2['% reads with an indel']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'wt indel %'] = row['% reads with an indel']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'edited indel %'] = row2['% reads with an indel']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'total edited reads'] = row2['total_reads']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'total wt reads'] = row['total_reads']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'edited reads with indels '] = row2['number of reads with indels']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'wt reads with indels'] = row['number of reads with indels']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'indel p-value'] = p_value\n",
    "        \n",
    "        \n",
    "    return comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0db33-3636-4019-9b50-9e112dac26a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comparison_tables = {'ALTC': [None, None],\n",
    "                     'ALT7': [None, None],\n",
    "                     'REX4': [None, None],\n",
    "                     'REXC': [None, None]}\n",
    "\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in [0,1]:\n",
    "        display(control_dfs[condition])\n",
    "        comparison_tables[condition][replicate] = construct_comp_tbl(control_dfs[condition], edited_dfs[condition][replicate])\n",
    "        comparison_tables[condition][replicate]['trial'] = replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ab01e-ddbb-466a-b7c7-6e26e90eaacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in np.arange(0,2):\n",
    "        comparison_tables[condition][replicate].to_csv(f\"{condition}_{replicate}consensus_comparison_hg38_new_con_filtered_mp20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d759980b-ee74-4805-a63c-6d09ec1eb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for condition in ['ALT7', 'ALTC', 'REXC', 'REX4']:\n",
    "    for replicate in np.arange(0,2):\n",
    "        comparison_tables[condition][replicate] = pd.read_csv(f\"{condition}_{replicate}consensus_comparison_hg38_con_filtered.csv\")\n",
    "        comparison_tables[condition][replicate]['trial'] = replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb3091-0200-42ac-80d9-9791a7dc7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comparison_tables = {'ALTC': None,\n",
    "                     'ALT7': None,\n",
    "                     'REX4': None,\n",
    "                     'REXC': None}\n",
    "\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    merged_comparison_tables[condition] = pd.concat([comparison_tables[condition][0], comparison_tables[condition][1]])\n",
    "    display(merged_comparison_tables[condition][merged_comparison_tables[condition]['REGION'] == 'REGION_0.bam'])\n",
    "    display(comparison_tables[condition][0])\n",
    "    display(comparison_tables[condition][1])\n",
    "    merged_comparison_tables[condition].to_csv(f\"{condition}consensus_merged_comparisond_con_new_hg38_filtered_mp20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca81da-f3cf-42d0-b9c9-506a132aeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(tbl):\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    # Color the first point differently by separating it\n",
    "    sns.scatterplot(\n",
    "        x=tbl[\"wt indel %\"].to_list()[1:],  # Exclude first point\n",
    "        y=tbl[\"edited indel %\"].to_list()[1:],  # Exclude first point\n",
    "        color='black',  # Makes the rest of the points black\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    # Plot the first point with a different color (e.g., red)\n",
    "    sns.scatterplot(\n",
    "        x=[tbl[\"wt indel %\"].to_list()[167]],  # on target point (change depending on the location and sample)\n",
    "        y=[tbl[\"edited indel %\"].to_list()[167]],  # on target point (change depending on the location and sample)\n",
    "        color='red',  # Different color for the first point\n",
    "        s=100,  # Increase size of first point\n",
    "        label=\"Edited Region (ALT7 Guide - chr9:27575447-27575470 )\"  # Optional: add label for legend\n",
    "    )\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Non-Edited Indel Percentage (%)\", fontsize=12)  # X-axis label\n",
    "    plt.ylabel(\"Edited Indel Percentage (%)\", fontsize=12)  # Y-axis label\n",
    "    plt.title(\"Indel Percentage Comparison: Non-Edited vs. Edited (Replicate 1)\", fontsize=14)  # Title\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.legend()  # Optional: to show the label in the legend\n",
    "    plt.show()\n",
    "\n",
    "# change depending on the table of interest\n",
    "tbl = comparison_tables['REX4'][0]\n",
    "display(tbl)\n",
    "plot_scatter(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cb6c5-8fe8-43d2-834f-dd481187af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np  # For histogram calculations\n",
    "\n",
    "# Extract the raw data from the DataFrame for CONTROL\n",
    "control_raw = control_dfs['REX4'][control_dfs['REX4']['REGION'] == 'REGION_14.bam']['deletion lengths'].to_list()\n",
    "if isinstance(control_raw, list) and len(control_raw) == 1 and isinstance(control_raw[0], str):\n",
    "    control_raw = ast.literal_eval(control_raw[0])  # Convert string to a proper list\n",
    "control_deletion_lengths = [x[0] for x in control_raw]  # Extract numbers from single-item lists\n",
    "\n",
    "# Extract the raw data from the DataFrame for EDITED (1)\n",
    "edited_raw_1 = edited_dfs['REX4'][0][edited_dfs['REX4'][0]['REGION'] == 'REGION_14.bam']['deletion lengths'].to_list()\n",
    "if isinstance(edited_raw_1, list) and len(edited_raw_1) == 1 and isinstance(edited_raw_1[0], str):\n",
    "    edited_raw_1 = ast.literal_eval(edited_raw_1[0])  # Convert string to a proper list\n",
    "edited_deletion_lengths_1 = [x[0] for x in edited_raw_1]  # Extract numbers from single-item lists\n",
    "\n",
    "# Extract the raw data from the DataFrame for EDITED (2)\n",
    "edited_raw_2 = edited_dfs['REX4'][1][edited_dfs['REX4'][1]['REGION'] == 'REGION_14.bam']['deletion lengths'].to_list()\n",
    "if isinstance(edited_raw_2, list) and len(edited_raw_2) == 1 and isinstance(edited_raw_2[0], str):\n",
    "    edited_raw_2 = ast.literal_eval(edited_raw_2[0])  # Convert string to a proper list\n",
    "edited_deletion_lengths_2 = [x[0] for x in edited_raw_2]  # Extract numbers from single-item lists\n",
    "\n",
    "# Calculate the bin range for all data\n",
    "all_deletion_lengths = edited_deletion_lengths_1 + edited_deletion_lengths_2 + control_deletion_lengths\n",
    "bin_range = range(min(all_deletion_lengths), max(all_deletion_lengths) + 1)\n",
    "bin_width = 1  # Set the width of the bins\n",
    "\n",
    "# Compute histogram values\n",
    "control_hist, bin_edges = np.histogram(control_deletion_lengths, bins=bin_range)\n",
    "edited_hist_1, _ = np.histogram(edited_deletion_lengths_1, bins=bin_range)\n",
    "edited_hist_2, _ = np.histogram(edited_deletion_lengths_2, bins=bin_range)\n",
    "\n",
    "# Set the positions for each dataset's bars\n",
    "width = 0.3  # Bar width\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # Get the center of each bin for placing bars\n",
    "\n",
    "# Create the combined histogram with bars side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the bars for the control dataset\n",
    "plt.bar(bin_centers - width, control_hist, width=width, alpha=0.7, color='red', edgecolor='black', label='Control')\n",
    "\n",
    "# Plot the bars for the first edited dataset\n",
    "plt.bar(bin_centers, edited_hist_1, width=width, alpha=0.7, color='blue', edgecolor='black', label='Edited 1')\n",
    "\n",
    "# Plot the bars for the second edited dataset\n",
    "plt.bar(bin_centers + width, edited_hist_2, width=width, alpha=0.7, color='cyan', edgecolor='black', label='Edited 2')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Deletion Length (bp)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Deletion Lengths On Target Region - REX4\")\n",
    "plt.legend()  # Add legend to differentiate between datasets\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149efde-89ae-4029-b278-9827e86679b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
