{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2126be8c-a7dd-4d6c-8f2e-be6713610967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pysam\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48ad3231-ae4f-41c5-95e5-f98c8b6a18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Clear the output of the current notebook\n",
    "clear_output(wait=True)\n",
    "\n",
    "# If you want to clear outputs from all cells, run this:\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.instance().run_line_magic('reset', '-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa69455c-ddbb-4f48-b3e4-44f9a8a61b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strandedness = []\n",
    "\n",
    "import argparse\n",
    "import pysam\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pysam\n",
    "fasta = pysam.FastaFile(\"hg38.fa\")\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.utils import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b86f9f43-7f3a-41bb-ae43-75626f27f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam\n",
    "from pathlib import Path\n",
    "\n",
    "#contains the locations of all the guides (lifted)\n",
    "altc = Path('small_bams_again') / 'beds'  / 'altc_lifted.bed'\n",
    "alt7 = Path('small_bams_again') / 'beds'  / 'alt7_lifted.bed'\n",
    "rex4 = Path('small_bams_again') / 'beds'  / 'rex4_lifted.bed'\n",
    "rexc = Path('small_bams_again') / 'beds' / 'rexc_lifted.bed'\n",
    "\n",
    "#all the dfs (at the moment) \n",
    "\n",
    "# ALT7 bams (not yet simulating) \n",
    "ALT7_1_BAMs = Path('small_bams_again') / 'ALT7_realigned' / 'rep1' / '7_prime_rep1_merged_sorted.bam'\n",
    "ALT7_2_BAMs = Path('small_bams_again') / 'ALT7_realigned' / 'rep2' / '7_prime_rep2_merged_sorted.bam'\n",
    "\n",
    "# ALTC bams\n",
    "ALTC_1_BAMs = Path('small_bams_again') / 'ALTC_realigned' / 'rep1' / 'c_prime_rep1_merged_sorted.bam'\n",
    "ALTC_2_BAMs = Path('small_bams_again') / 'ALTC_realigned' / 'rep2' / 'c_prime_rep2_merged_sorted.bam'\n",
    "\n",
    "# REXC bams\n",
    "REXC_1_BAMs = Path('small_bams_again') / 'REXC_realigned' / 'rep1' / 'c_rep1_merged_sorted.bam'\n",
    "REXC_2_BAMs = Path('small_bams_again') / 'REXC_realigned' / 'rep2' / 'c_rep2_merged_sorted.bam'\n",
    "\n",
    "# REX4 bams\n",
    "REX4_2_BAMs = Path('small_bams_again') / 'REX4_realigned' / 'rep1' / '4_rep1_merged_sorted.bam'\n",
    "REX4_3_BAMs = Path('small_bams_again') / 'REX4_realigned' / 'rep2' / '4_rep2_merged_sorted.bam'\n",
    "\n",
    "\n",
    "ALTC_NO_NUNC = Path('small_bams_again') / 'ALTC_realigned' / 'nuc' / 'c_nuc_merged_sorted.bam'\n",
    "REX4_NO_NUNC = Path('small_bams_again') / 'REX4_realigned' / 'nuc' / '4_nuc_merged_sorted.bam'\n",
    "ALT7_NO_NUNC = Path('small_bams_again') / 'ALT7_realigned' / 'nuc' / '7_nuc_merged_sorted.bam'\n",
    "REXC_NO_NUNC = Path('small_bams_again') / 'REXC_realigned' / 'nuc' / 'c_nuc_merged_sorted.bam'\n",
    "\n",
    "\n",
    "\n",
    "# Function to read BAM files from a directory and store in a dictionary\n",
    "#currently the BAM file is stored in memory (which could lead to memory issues) -->\n",
    "#rather than save the entire BAM file (and open it - save the path to the PAM file and do downstream analysis)\n",
    "def read_bam_files_to_dict(directory):\n",
    "    bam_files_dict = {}\n",
    "    \n",
    "    #sort the directory by name\n",
    "    sorted_bam_files = sorted(directory.glob('*.bam'), key=lambda f: f.name)\n",
    "    \n",
    "    for bam_file in sorted_bam_files:  # Filter for .bam files\n",
    "        #bam = pysam.AlignmentFile(bam_file, \"rb\") \n",
    "        bam_files_dict[bam_file.name] = bam_file.resolve() # Store filename as key, BAM object as value\n",
    "    return bam_files_dict\n",
    "\n",
    "# Read BAM files from each directory\n",
    "\n",
    "#ALTC\n",
    "bam_files_AltC_1 = read_bam_files_to_dict(ALTC_1_BAMs)\n",
    "bam_files_AltC_2 = read_bam_files_to_dict(ALTC_2_BAMs)\n",
    "\n",
    "#ALT7\n",
    "bam_files_Alt7_1 = read_bam_files_to_dict(ALT7_1_BAMs)\n",
    "bam_files_Alt7_2 = read_bam_files_to_dict(ALT7_2_BAMs)\n",
    "\n",
    "#REX4\n",
    "bam_files_REX4_2 = read_bam_files_to_dict(REX4_2_BAMs)\n",
    "bam_files_REX4_3 = read_bam_files_to_dict(REX4_3_BAMs)\n",
    "\n",
    "#REXC\n",
    "bam_files_REXC_1 = read_bam_files_to_dict(REXC_1_BAMs)\n",
    "bam_files_REXC_2 = read_bam_files_to_dict(REXC_2_BAMs)\n",
    "\n",
    "#NO_NUNC \n",
    "bam_files_NO_NUNC_ALTC = read_bam_files_to_dict(ALTC_NO_NUNC)\n",
    "bam_files_NO_NUNC_ALT7 = read_bam_files_to_dict(ALT7_NO_NUNC)\n",
    "bam_files_NO_NUNC_REX4 = read_bam_files_to_dict(REX4_NO_NUNC)\n",
    "bam_files_NO_NUNC_REXC = read_bam_files_to_dict(REXC_NO_NUNC)\n",
    "\n",
    "\n",
    "#THE BAM FILES TO CONSIDER\n",
    "#refactor to account for a merged bam instead\n",
    "all_bams = {'ALTC': [ALTC_1_BAMs, ALTC_2_BAMs],\n",
    "            'ALT7': [ALT7_1_BAMs, ALT7_2_BAMs],\n",
    "            'REX4': [REX4_2_BAMs, REX4_3_BAMs],\n",
    "            'REXC': [REXC_1_BAMs, REXC_2_BAMs]}\n",
    "\n",
    "#THE CONTROL BAMS\n",
    "all_controls = {'ALTC':ALTC_NO_NUNC,\n",
    "                'ALT7':ALT7_NO_NUNC,\n",
    "                'REX4':REX4_NO_NUNC,\n",
    "                'REXC':REXC_NO_NUNC}\n",
    "\n",
    "#TSVs for the locations of the potential locations\n",
    "all_tsvs = {'ALTC':pd.read_csv(altc, sep='\\t',  names=['chrom','start','end','name','na','na2','REGION'])[:],\n",
    "                'ALT7':pd.read_csv(alt7, sep='\\t',  names=['chrom','start','end','na','na2','REGION'])[:],\n",
    "                'REX4':pd.read_csv(rex4, sep='\\t',  names=['chrom','start','end','na','na2','REGION'])[:],\n",
    "                'REXC':pd.read_csv(rexc, sep='\\t',  names=['chrom','start','end','na','na2','REGION'])[:]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#NO_NUNC \n",
    "bam_files_NO_NUNC_ALTC = read_bam_files_to_dict(ALTC_NO_NUNC)\n",
    "bam_files_NO_NUNC_ALT7 = read_bam_files_to_dict(ALT7_NO_NUNC)\n",
    "bam_files_NO_NUNC_REX4 = read_bam_files_to_dict(REX4_NO_NUNC)\n",
    "bam_files_NO_NUNC_REXC = read_bam_files_to_dict(REXC_NO_NUNC)\n",
    "\n",
    "all_controls = {'ALTC':ALTC_NO_NUNC,\n",
    "                'ALT7':ALT7_NO_NUNC,\n",
    "                'REX4':REX4_NO_NUNC,\n",
    "                'REXC':REXC_NO_NUNC}\n",
    "\n",
    "#iterate through all the tsvs and make a \"REGION' entry\n",
    "for condition in all_tsvs:\n",
    "    all_tsvs[condition]['REGION'] = ['REGION_' + str(i) + '.bam' for i in np.arange(0,  all_tsvs[condition]['REGION'].shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d421ebf-78ae-45b8-9717-c21c146f364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_read = None\n",
    "\n",
    "#this finds the deletions given a specific inbam (don't need to modify)\n",
    "def find_deletion_locs(inbam, chrom, start_loc, end_loc,strand):\n",
    "    deletions = []\n",
    "    insertions = []\n",
    "    #table of all indels (-) for a feletion (+) for an insertion\n",
    "    indels = []\n",
    "    count = 0\n",
    "    \n",
    "    #iterate through the inbam \n",
    "    for read in inbam.fetch(chrom, start_loc, end_loc):\n",
    "        \n",
    "        deletion_lst = []\n",
    "        insertion_lst = []\n",
    "        indel_lst = []\n",
    "\n",
    "        count += 1\n",
    "        ref_start = read.reference_start  # Correct attribute for reference start position\n",
    "\n",
    "        #if the start of the read is soft clipped\n",
    "        if read.is_unmapped:\n",
    "            print(chrom, start_loc, end_loc)\n",
    "            print('UNMAPPED')\n",
    "            break\n",
    "        if read.cigartuples[0][0] == 4:\n",
    "            #make the location of the read start at the reference minus the length of the soft clipping as reference_start doesn't\n",
    "            #otherwise include the soft clipped bases \n",
    "            ref_start = ref_start - read.cigartuples[0][1] \n",
    "        \n",
    "        cigar = read.cigartuples\n",
    "    \n",
    "        #the bases traversed - where we are in the read \n",
    "        l_read = 0\n",
    "        \n",
    "        #the exact start position of the read - where we are in the reference \n",
    "        l = ref_start\n",
    "        segment_index = 0\n",
    "\n",
    "        # if start_loc == 27573507:\n",
    "        #     print(cigar)\n",
    "        #     print(ref_start)\n",
    "\n",
    "        #go through now the entire cigar array\n",
    "        for op, length in cigar:\n",
    "\n",
    "            if strand == '-':\n",
    "                #on the 3' end\n",
    "                if length + l > start_loc and l < start_loc:\n",
    "                    if op == 2:\n",
    "                        # print(\"Deletion found\")\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                #on the 5' end\n",
    "                elif l + length > end_loc and l < end_loc:\n",
    "                    if op == 2:\n",
    "                        # print(\"deletion found\")\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                #starts in the region\n",
    "                elif l >= start_loc and l <= end_loc:\n",
    "                    if op == 2:\n",
    "                        # print(\"deletion found\")\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                #deletuon ends in the region\n",
    "                elif l + length >= start_loc and l + length  <= end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "\n",
    "            #deletion should be on the 3' end (at the end)\n",
    "            if strand == '+' or strand == 'unknown':\n",
    "                # if start_loc == 27573507:\n",
    "                #     print('got at least the strand')\n",
    "                if length + l > end_loc and l < end_loc:\n",
    "                    if op == 2:\n",
    "                        # print(\"deletion found\")\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                        #may 8th - put an equal sign \n",
    "                elif length + l > start_loc and l < start_loc:\n",
    "                    if op == 2:\n",
    "                        # print(\"Deletion found\")\n",
    "                        deletion_lst.append([\"deletions extending passed region\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                #deletion starts in the region\n",
    "                elif l >= start_loc and l  <= end_loc:\n",
    "                    if op == 2:\n",
    "                        # print(\"deletion found\")\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "                #deletion ends in the region\n",
    "                elif l + length >= start_loc and l + length  <= end_loc:\n",
    "                    if op == 2:\n",
    "                        deletion_lst.append([\"deletions\", length, (l, l+length)])\n",
    "                        indel_lst.append([\"indels\", -1 * length])\n",
    "\n",
    "            #insertion ends in the guide loc\n",
    "            if l + length < end_loc and l + length > start_loc :\n",
    "                if op == 1:\n",
    "                    insertion_lst.append([\"insertions\", length, (l, l+length)])\n",
    "                    indel_lst.append([\"indels\", length])\n",
    "                    \n",
    "            #insertion begins in the guide loc\n",
    "            if l  < end_loc and l > start_loc :\n",
    "                if op == 1:\n",
    "                    insertion_lst.append([\"insertions\", length, (l, l+length)])\n",
    "                    indel_lst.append([\"indels\", length])\n",
    "                \n",
    "            \n",
    "            '''below traverses the region of the read we are considering'''\n",
    "            if op == 0:  # NOT SURE WHAT THE MEANING OF THIS IS\n",
    "                l_read += length\n",
    "                l += length\n",
    "\n",
    "            #THIS SEEMS STRANGE -- BUT THIS ALSO WORKED? SO NOW I AM CONFUSED ARGH\n",
    "            elif op == 1:  # Insertion (this is correct)\n",
    "                l_read += length\n",
    "                \n",
    "            elif op == 2:  # Deletion (this is correct)\n",
    "                # print('here')\n",
    "                # if start_loc == 27573507:\n",
    "                #     print(l, l+length)\n",
    "                #     print(start_loc, end_loc)\n",
    "                l += length \n",
    "                \n",
    "            elif op == 3:  # Skipped region\n",
    "                l += length #moving ahead in the reference\n",
    "                \n",
    "            elif op == 4:  # Soft clipping\n",
    "                l_read += length\n",
    "                l += length #\n",
    "                \n",
    "            elif op == 5:  # Hard clipping NOT SURE \n",
    "                pass\n",
    "            elif op == 6:  # Padding NOT SURE \n",
    "                pass\n",
    "            elif op == 7:  # Segment equal (this is correct)\n",
    "                l_read += length\n",
    "                l += length\n",
    "                \n",
    "            elif op == 8:  # seems to be sequence mismatcj - they both advance then NOT SURE\n",
    "                l_read += length\n",
    "                l += length\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown CIGAR operation code {op}\")\n",
    "\n",
    "            #if - once adding the oppcode have suprased the end of the read - break\n",
    "            if l > end_loc:\n",
    "                if len(deletion_lst) > 0:\n",
    "                    deletions.append(deletion_lst)\n",
    "                if len(insertion_lst) > 0:\n",
    "                    insertions.append(insertion_lst)\n",
    "                if len(indel_lst) > 0:\n",
    "                    indels.append(indel_lst)\n",
    "                break\n",
    "                \n",
    "            segment_index += 1\n",
    "            \n",
    "\n",
    "    #returns a list of all the deletions and all the insertions and a total indel lst\n",
    "    return deletions, insertions, indels\n",
    "            \n",
    "    # Close the BAM file\n",
    "    inbam.close()\n",
    "\n",
    "\n",
    "#goes through a locations list \n",
    "def construct_df(locations, bam_file, del_lst, ins_lst, indel_lst):\n",
    "    print('locations', locations)\n",
    "    locations = locations.copy()    \n",
    "    count = 0\n",
    "    #iterates through the bams \n",
    "    for index, row in locations.iterrows():\n",
    "        \n",
    "        region = row['REGION']\n",
    "        if count % 1000 == 0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "\n",
    "        inbam = pysam.AlignmentFile(bam_file, \"rb\")  # Store filename as key, BAM object as value\n",
    "        \n",
    "        chrom = locations[locations['REGION'] == region]['chrom'].tolist()[0]\n",
    "        start = locations[locations['REGION'] == region]['start'].tolist()[0]\n",
    "        end = locations[locations['REGION'] == region]['end'].tolist()[0]\n",
    "\n",
    "        #modifying this so open BAMs etc\n",
    "        deletions = del_lst[region]\n",
    "        indels = indel_lst[region]\n",
    "        \n",
    "        deletion_lengths = [\n",
    "            [deletion[1] for deletion in read if 'deletions' in deletion[0]]\n",
    "            for read in deletions\n",
    "        ]\n",
    "\n",
    "        deletion_coords = [\n",
    "            [deletion[2] for deletion in read if 'deletions' in deletion[0]]\n",
    "            for read in deletions\n",
    "        ]\n",
    "\n",
    "        #keep track of the number of indels\n",
    "        indel_lengths = [\n",
    "            [indel[1] for indel in read if 'indel' in indel[0]]\n",
    "            for read in indels\n",
    "        ]\n",
    "        \n",
    "        num_deletions = len(deletion_lengths)\n",
    "\n",
    "        deletion_extending_past_region_lengths = [deletion[1] for read in deletions for deletion in read if 'extending' in deletion[0]]\n",
    "        deletion_extending_past_region_coords = [deletion[2] for read in deletions for deletion in read if 'extending' in deletion[0]]\n",
    "        num_deletions_extending_past_region = len(deletion_extending_past_region_coords)\n",
    "        \n",
    "        insertions = ins_lst[region]\n",
    "        \n",
    "        #insertion_lengths = [insertion[1] for read in insertions for insertion in read if 'insertions' == insertion[0]]\n",
    "        insertion_lengths = [\n",
    "            [insertion[1] for insertion in read if 'insertions' in insertion[0]]\n",
    "            for read in insertions \n",
    "        ]\n",
    "        \n",
    "        insertion_coords = [\n",
    "            [insertion[2] for insertion in read if 'insertions' in insertion[0]]\n",
    "            for read in insertions\n",
    "        ]\n",
    "        \n",
    "        #insertion_coords = [insertion[2] for read in insertions for insertion in read if 'insertions' == insertion[0]]\n",
    "        num_insertions = len(insertion_coords)\n",
    "        num_indels = len(indel_lengths)\n",
    "\n",
    "        #adding some columns to the dataframes\n",
    "        total_reads = sum(1 for read in inbam.fetch(chrom, int(start), int(end)))\n",
    "        \n",
    "        locations.loc[locations['REGION'] == region, 'total_reads'] = total_reads\n",
    "        locations.loc[locations['REGION'] == region, 'forward_reads'] = sum(1 for read in inbam.fetch(chrom, int(start), int(end)) if not read.is_reverse)\n",
    "        locations.loc[locations['REGION'] == region, 'reverse_reads'] = sum(1 for read in inbam.fetch(chrom, int(start), int(end)) if read.is_reverse)\n",
    "\n",
    "        if region == 'REGION_7126.bam':\n",
    "            print(total_reads)\n",
    "                    \n",
    "        #collect info about all deletions\n",
    "        locations.loc[locations['REGION'] == region, 'deletion lengths'] = str(deletion_lengths)\n",
    "        locations.loc[locations['REGION'] == region, 'deletion coords'] = str(deletion_coords)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with deletion(s)'] = str(num_deletions)\n",
    "        #collect info about all insertions\n",
    "        locations.loc[locations['REGION'] == region, 'insertion lengths'] = str(insertion_lengths)\n",
    "        locations.loc[locations['REGION'] == region, 'insertion coords'] = str(insertion_coords)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with insertion(s)'] = str(num_insertions)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with indels'] = str(num_indels)     \n",
    "\n",
    "\n",
    "        #collect info about all deletions that go past the guide site\n",
    "        locations.loc[locations['REGION'] == region, 'deletion extending past region lengths'] = str(deletion_extending_past_region_lengths)\n",
    "        locations.loc[locations['REGION'] == region, 'deletion extending past region coords'] = str(deletion_extending_past_region_coords)\n",
    "        locations.loc[locations['REGION'] == region, 'number of reads with deletion extending past region'] = str(num_deletions_extending_past_region)     \n",
    "\n",
    "        if total_reads != 0:\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an deletion'] = int(num_deletions) / int(total_reads)\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an insertion'] = int(num_insertions) / int(total_reads)\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an indel'] = int(num_indels) / int(total_reads)\n",
    "        else:\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an insertion'] = None\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an deletion'] = None\n",
    "            locations.loc[locations['REGION'] == region, '% reads with an indel'] = None\n",
    "        #close the bam file\n",
    "        inbam.close()\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e165b86-5ce8-4c55-8c85-232fa8b0fdda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALTC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>name</th>\n",
       "      <th>na</th>\n",
       "      <th>na2</th>\n",
       "      <th>REGION</th>\n",
       "      <th>strandedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr3</td>\n",
       "      <td>81731576</td>\n",
       "      <td>81731598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_0.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr4</td>\n",
       "      <td>53055073</td>\n",
       "      <td>53055095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_1.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chrX</td>\n",
       "      <td>54602603</td>\n",
       "      <td>54602626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>67440184</td>\n",
       "      <td>67440206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_3.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr7</td>\n",
       "      <td>152135028</td>\n",
       "      <td>152135050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_4.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>chr8</td>\n",
       "      <td>118489859</td>\n",
       "      <td>118489882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_328.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>chr21</td>\n",
       "      <td>30914949</td>\n",
       "      <td>30914972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_329.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>chr11</td>\n",
       "      <td>116585793</td>\n",
       "      <td>116585816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_330.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>chr11</td>\n",
       "      <td>11274660</td>\n",
       "      <td>11274683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_331.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>chr13</td>\n",
       "      <td>105083059</td>\n",
       "      <td>105083082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_332.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chrom      start        end  name  na  na2          REGION strandedness\n",
       "0     chr3   81731576   81731598   NaN NaN  NaN    REGION_0.bam      unknown\n",
       "1     chr4   53055073   53055095   NaN NaN  NaN    REGION_1.bam      unknown\n",
       "2     chrX   54602603   54602626   NaN NaN  NaN    REGION_2.bam      unknown\n",
       "3     chr1   67440184   67440206   NaN NaN  NaN    REGION_3.bam      unknown\n",
       "4     chr7  152135028  152135050   NaN NaN  NaN    REGION_4.bam      unknown\n",
       "..     ...        ...        ...   ...  ..  ...             ...          ...\n",
       "328   chr8  118489859  118489882   NaN NaN  NaN  REGION_328.bam      unknown\n",
       "329  chr21   30914949   30914972   NaN NaN  NaN  REGION_329.bam      unknown\n",
       "330  chr11  116585793  116585816   NaN NaN  NaN  REGION_330.bam      unknown\n",
       "331  chr11   11274660   11274683   NaN NaN  NaN  REGION_331.bam      unknown\n",
       "332  chr13  105083059  105083082   NaN NaN  NaN  REGION_332.bam      unknown\n",
       "\n",
       "[333 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALT7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>na</th>\n",
       "      <th>na2</th>\n",
       "      <th>REGION</th>\n",
       "      <th>strandedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr8</td>\n",
       "      <td>6125767</td>\n",
       "      <td>6125791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_0.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>153344375</td>\n",
       "      <td>153344398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_1.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>10813057</td>\n",
       "      <td>10813081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr7</td>\n",
       "      <td>100921222</td>\n",
       "      <td>100921246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_3.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>34737411</td>\n",
       "      <td>34737434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_4.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>chr7</td>\n",
       "      <td>140179543</td>\n",
       "      <td>140179566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2039.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>chr6</td>\n",
       "      <td>20173116</td>\n",
       "      <td>20173139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2040.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>chr2</td>\n",
       "      <td>86022567</td>\n",
       "      <td>86022590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2041.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>chr2</td>\n",
       "      <td>75125534</td>\n",
       "      <td>75125556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2042.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>chr6</td>\n",
       "      <td>11626340</td>\n",
       "      <td>11626363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2043.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chrom      start        end  na  na2           REGION strandedness\n",
       "0     chr8    6125767    6125791 NaN  NaN     REGION_0.bam      unknown\n",
       "1     chr1  153344375  153344398 NaN  NaN     REGION_1.bam      unknown\n",
       "2     chr1   10813057   10813081 NaN  NaN     REGION_2.bam      unknown\n",
       "3     chr7  100921222  100921246 NaN  NaN     REGION_3.bam      unknown\n",
       "4     chr1   34737411   34737434 NaN  NaN     REGION_4.bam      unknown\n",
       "...    ...        ...        ...  ..  ...              ...          ...\n",
       "2039  chr7  140179543  140179566 NaN  NaN  REGION_2039.bam      unknown\n",
       "2040  chr6   20173116   20173139 NaN  NaN  REGION_2040.bam      unknown\n",
       "2041  chr2   86022567   86022590 NaN  NaN  REGION_2041.bam      unknown\n",
       "2042  chr2   75125534   75125556 NaN  NaN  REGION_2042.bam      unknown\n",
       "2043  chr6   11626340   11626363 NaN  NaN  REGION_2043.bam      unknown\n",
       "\n",
       "[2044 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REXC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>na</th>\n",
       "      <th>na2</th>\n",
       "      <th>REGION</th>\n",
       "      <th>strandedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>28594989</td>\n",
       "      <td>28595011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_0.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr15</td>\n",
       "      <td>94909979</td>\n",
       "      <td>94910002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_1.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr16</td>\n",
       "      <td>5625250</td>\n",
       "      <td>5625273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr5</td>\n",
       "      <td>135883747</td>\n",
       "      <td>135883770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_3.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr19</td>\n",
       "      <td>32985142</td>\n",
       "      <td>32985165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_4.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>chr6</td>\n",
       "      <td>1610013</td>\n",
       "      <td>1610036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2575.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>chr1</td>\n",
       "      <td>36486968</td>\n",
       "      <td>36486991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2576.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>chrX</td>\n",
       "      <td>80805788</td>\n",
       "      <td>80805810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2577.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1185685</td>\n",
       "      <td>1185708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2578.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>chr7</td>\n",
       "      <td>151251860</td>\n",
       "      <td>151251883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2579.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2580 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chrom      start        end  na  na2           REGION strandedness\n",
       "0      chr1   28594989   28595011 NaN  NaN     REGION_0.bam      unknown\n",
       "1     chr15   94909979   94910002 NaN  NaN     REGION_1.bam      unknown\n",
       "2     chr16    5625250    5625273 NaN  NaN     REGION_2.bam      unknown\n",
       "3      chr5  135883747  135883770 NaN  NaN     REGION_3.bam      unknown\n",
       "4     chr19   32985142   32985165 NaN  NaN     REGION_4.bam      unknown\n",
       "...     ...        ...        ...  ..  ...              ...          ...\n",
       "2575   chr6    1610013    1610036 NaN  NaN  REGION_2575.bam      unknown\n",
       "2576   chr1   36486968   36486991 NaN  NaN  REGION_2576.bam      unknown\n",
       "2577   chrX   80805788   80805810 NaN  NaN  REGION_2577.bam      unknown\n",
       "2578   chr1    1185685    1185708 NaN  NaN  REGION_2578.bam      unknown\n",
       "2579   chr7  151251860  151251883 NaN  NaN  REGION_2579.bam      unknown\n",
       "\n",
       "[2580 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REX4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>na</th>\n",
       "      <th>na2</th>\n",
       "      <th>REGION</th>\n",
       "      <th>strandedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr11</td>\n",
       "      <td>15300594</td>\n",
       "      <td>15300617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_0.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr21</td>\n",
       "      <td>45329598</td>\n",
       "      <td>45329621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_1.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr5</td>\n",
       "      <td>167196910</td>\n",
       "      <td>167196933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_2.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr20</td>\n",
       "      <td>51269529</td>\n",
       "      <td>51269552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_3.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>56258174</td>\n",
       "      <td>56258196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_4.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>chrX</td>\n",
       "      <td>56588923</td>\n",
       "      <td>56588946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_177.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>chr12</td>\n",
       "      <td>123801871</td>\n",
       "      <td>123801895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_178.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>chr13</td>\n",
       "      <td>24241712</td>\n",
       "      <td>24241735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_179.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>chr12</td>\n",
       "      <td>68285106</td>\n",
       "      <td>68285129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_180.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>chr16</td>\n",
       "      <td>11265372</td>\n",
       "      <td>11265395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGION_181.bam</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chrom      start        end  na  na2          REGION strandedness\n",
       "0    chr11   15300594   15300617 NaN  NaN    REGION_0.bam      unknown\n",
       "1    chr21   45329598   45329621 NaN  NaN    REGION_1.bam      unknown\n",
       "2     chr5  167196910  167196933 NaN  NaN    REGION_2.bam      unknown\n",
       "3    chr20   51269529   51269552 NaN  NaN    REGION_3.bam      unknown\n",
       "4     chr1   56258174   56258196 NaN  NaN    REGION_4.bam      unknown\n",
       "..     ...        ...        ...  ..  ...             ...          ...\n",
       "177   chrX   56588923   56588946 NaN  NaN  REGION_177.bam      unknown\n",
       "178  chr12  123801871  123801895 NaN  NaN  REGION_178.bam      unknown\n",
       "179  chr13   24241712   24241735 NaN  NaN  REGION_179.bam      unknown\n",
       "180  chr12   68285106   68285129 NaN  NaN  REGION_180.bam      unknown\n",
       "181  chr16   11265372   11265395 NaN  NaN  REGION_181.bam      unknown\n",
       "\n",
       "[182 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "import logging\n",
    "import warnings\n",
    "import pysam\n",
    "\n",
    "# Suppress warnings\n",
    "logging.getLogger(\"pysam\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\", message=\"hts_idx_load3\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "guide_sequence = \"TAGTAATAGTACCTAATGTG\"\n",
    "strandedness = []\n",
    "\n",
    "#GOES THROUGH ALL THE TSV FILES (THAT CONTAIN INFORMATION ABOUT THE CHANGE SEQ LOCATIONS - AND EXTRACT INFORMATION ABOUT THE \n",
    "#STRANDNEDNESS (NOT REALLY SURE THIS INFORMATION IS RELEVANT - BUT DO IT ANYWAYS)\n",
    "\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    print(condition)\n",
    "    strandedness = []\n",
    "    \n",
    "    # for index, row in all_tsvs[condition].iterrows():\n",
    "        \n",
    "    #     # print(index)\n",
    "    #     # if index == 8900:\n",
    "    #     #     print(row)\n",
    "        \n",
    "    #     ref_sequence = fasta.fetch(row['chrom'], int(row['start']), int(row['end'])).upper()\n",
    "    #     ref_complement = str(Seq(ref_sequence).reverse_complement())\n",
    "        \n",
    "    #     # Align guide sequence with reference and reference complement\n",
    "    #     align_ref = pairwise2.align.globalxx(guide_sequence, ref_sequence)\n",
    "    #     align_complement = pairwise2.align.globalxx(guide_sequence, ref_complement)\n",
    "        \n",
    "    #     # Calculate homology scores\n",
    "    #     score_ref = align_ref[0][2] if align_ref else 0\n",
    "    #     score_complement = align_complement[0][2] if align_complement else 0\n",
    "        \n",
    "    #     # Determine strandedness based on higher homology score\n",
    "    #     if score_ref > score_complement:\n",
    "    #         strand = '+'\n",
    "    #     elif score_complement > score_ref:\n",
    "    #         strand = '-'\n",
    "    #     else:\n",
    "    #         strand = \"unknown\"\n",
    "        \n",
    "    #     strandedness.append(strand)\n",
    "    \n",
    "    \n",
    "    #not sure if this is accurate - the location of the off target on the strand is used to see where the deletion should be once aligned\n",
    "    #the reads are reverse complemented (mention this)\n",
    "    all_tsvs[condition]['strandedness'] = 'unknown'\n",
    "    display(all_tsvs[condition])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e39e3-f550-4c9d-8da0-587030901ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "all_del_dict = {'ALTC':[{},{}],'ALT7':[{},{}],'REXC':[{},{}],'REX4':[{},{}]}\n",
    "all_ins_dict = {'ALTC':[{},{}],'ALT7':[{},{}],'REXC':[{},{}],'REX4':[{},{}]}\n",
    "all_ind_dict = {'ALTC':[{},{}],'ALT7':[{},{}],'REXC':[{},{}],'REX4':[{},{}]}\n",
    "\n",
    "#goes through all conditions, all bams and all replicates - extracts each region analyzed and populates dictionary with\n",
    "#seems like all the issues are with the AltC2 replicate\n",
    "\n",
    "for condition in ['REXC', 'REX4', 'ALTC', 'ALT7']:\n",
    "    condition_bams = all_bams[condition]\n",
    "    tsv = all_tsvs[condition]    \n",
    "    #display(tsv)\n",
    "    replicate_num = 0\n",
    "\n",
    "    #go through each replicate\n",
    "    for replicate in condition_bams:\n",
    "        count = 0\n",
    "        inbam = replicate      \n",
    "        for region in all_tsvs[condition]['REGION']:         \n",
    "            bam_basename = ''\n",
    "    \n",
    "            if count % 1000 == 0:\n",
    "                print(count)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            #how to properly extract the coordinates?\n",
    "            chrom = tsv[tsv['REGION'] == region]['chrom'].tolist()[0]\n",
    "            start = tsv[tsv['REGION'] == region]['start'].tolist()[0]\n",
    "            end = tsv[tsv['REGION'] == region]['end'].tolist()[0]\n",
    "\n",
    "            strand = 'unknown'\n",
    "            bam_file = pysam.AlignmentFile(inbam, \"rb\") \n",
    "\n",
    "            #instead of passing in the bam_file itself passing in a name to the bam_file and then should close it\n",
    "            all_del_dict[condition][replicate_num][region],all_ins_dict[condition][replicate_num][region], all_ind_dict[condition][replicate_num][region] = find_deletion_locs(bam_file, chrom, int(start), int(end), strand)\n",
    "                #close the bam_file    \n",
    "        \n",
    "            bam_file.close()  # Close the BAM file\n",
    "        replicate_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b881027f-5932-41aa-8d37-be51ef866083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## all_del_dict_wt = {'ALTC':{},'ALT7':{},'REXC':{},'REX4':{}}\n",
    "all_ins_dict_wt = {'ALTC':{},'ALT7':{},'REXC':{},'REX4':{}}\n",
    "all_ind_dict_wt = {'ALTC':{},'ALT7':{},'REXC':{},'REX4':{}}\n",
    "\n",
    "#goes through all conditions, all bams and all replicates - extracts each region analyzed and gets the insertion etc\n",
    "#this is just for the control subset\n",
    "\n",
    "#seems to be appropriatly populating\n",
    "for condition in [\"ALTC\", \"REXC\", \"REX4\", \"ALT7\"]:\n",
    "    condition_bams = all_controls[condition]\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    display(all_tsvs[condition])\n",
    "    \n",
    "    inbam = condition_bams    \n",
    "    for region in all_tsvs[condition]['REGION']:\n",
    "        if count % 1000 == 0:\n",
    "            print(condition)\n",
    "            print(count)\n",
    "                \n",
    "        count += 1\n",
    "\n",
    "        chrom = all_tsvs[condition][all_tsvs[condition]['REGION'] == region]['chrom'].tolist()[0]\n",
    "        start = all_tsvs[condition][all_tsvs[condition]['REGION'] == region]['start'].tolist()[0]\n",
    "        end = all_tsvs[condition][all_tsvs[condition]['REGION'] == region]['end'].tolist()[0]\n",
    "                    \n",
    "        #open the bam_file\n",
    "        bam_file = pysam.AlignmentFile(inbam, \"rb\") \n",
    "        #instead of passing in the bam_file itself passing in a name to the bam_file and then should close it\n",
    "        \n",
    "        all_del_dict_wt[condition][region],all_ins_dict_wt[condition][region], all_ind_dict_wt[condition][region] = find_deletion_locs(bam_file, chrom, int(start), int(end), strand)\n",
    "        bam_file.close()  # Close the BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993aa3e-9ae1-4644-91a1-357664bda446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_del_dict_wt['ALTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e39c2-56c8-4f5c-904c-30cd2669a594",
   "metadata": {},
   "outputs": [],
   "source": [
    " edited_dfs[condition][replicate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4b73f-e33d-4377-991b-332b71f73533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edited_dfs = {'ALTC': [None, None],\n",
    "      'ALT7': [None, None],\n",
    "      'REXC': [None, None],\n",
    "      'REX4':[None, None]}\n",
    "\n",
    "control_dfs = {'ALTC': None,\n",
    "      'ALT7': None,\n",
    "      'REXC': None,\n",
    "      'REX4': None}\n",
    "\n",
    "#iterate through the conditions (ALTC, ALT7, REX4, and REXC) and then create tables\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    print(all_bams[condition][replicate])\n",
    "    for replicate in np.arange(0,2):\n",
    "        edited_dfs[condition][replicate] = construct_df(all_tsvs[condition],all_bams[condition][replicate], all_del_dict[condition][replicate],\n",
    "                     all_ins_dict[condition][replicate], all_ind_dict[condition][replicate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278b965-f9aa-475b-8515-46613197f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct all the dataframes for the insertions/deletions/indels present in the control (no nucleoinfection) group\n",
    "#in this case there are NOT replicates\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    control_dfs[condition] = construct_df(all_tsvs[condition],all_controls[condition], all_del_dict_wt[condition],\n",
    "                 all_ins_dict_wt[condition], all_ind_dict_wt[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4cc39e-42fe-485f-a520-520d3e03da9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in  np.arange(0,2):\n",
    "        df = edited_dfs[condition][replicate]\n",
    "        display(df)\n",
    "        print(condition)\n",
    "        print(replicate)\n",
    "        df.to_csv(str(condition) + 'new_concatanted_taylor_consensus_indel_rates_hg38' + str(replicate) + '.csv', index=False)  # Set index=True if you want to keep the index\n",
    "\n",
    "\n",
    "for condition in ['ALTC','ALT7', 'REXC', 'REX4']:\n",
    "    df = control_dfs[condition]\n",
    "    print(condition)\n",
    "    display(df)\n",
    "    df.to_csv(str(condition) + 'new_concatanted_taylor_consensus_indel_rates_control_hg38' + '.csv', index=False)  # Set index=True if you want to keep the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677924cb-a230-40aa-baa3-e91da24d9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the csvs and populate tables so don't have to redo it all \n",
    "\n",
    "# # edited_dfs = {'ALTC': [None, None],\n",
    "# #       'ALT7': [None, None],\n",
    "# #       'REXC': [None, None],\n",
    "# #       'REX4':[None, None]}\n",
    "\n",
    "# # control_dfs = {'ALTC': None,\n",
    "# #       'ALT7': None,\n",
    "# #       'REXC': None,\n",
    "#       'REX4': None}\n",
    "\n",
    "# for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "#     for replicate in  np.arange(0,2):\n",
    "#         file_path = f\"{condition}consensus_indel_rates_hg38_new_con{replicate}.csv\"  # Construct file name\n",
    "#         print(file_path)\n",
    "#         edited_dfs[condition][replicate] = pd.read_csv(file_path)\n",
    "\n",
    "# for condition in ['ALTC','ALT7', 'REXC', 'REX4']:\n",
    "#     file_path = f\"{condition}consensus_indel_rates_control_hg38_new_con.csv\"  # Using f-string for readability\n",
    "#     print(file_path)\n",
    "#     control_dfs['ALTC'] = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef2e4d-9fa8-4d0a-87bc-2863d06a165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "def construct_comp_tbl(wt, edited):\n",
    "    comp_df = pd.DataFrame([])\n",
    "\n",
    "    # Ensure 'REGION' column is included\n",
    "    comp_df['REGION'] = wt['REGION'].tolist()\n",
    "    \n",
    "\n",
    "    #construct a contigency table\n",
    "    for index, row in wt.iterrows():\n",
    "        # display(row)\n",
    "        cont = pd.DataFrame([])\n",
    "        cont_indel = pd.DataFrame([])\n",
    "        \n",
    "        region = row['REGION']\n",
    "        cont['wt'] = [int(row['number of reads with indels']),\n",
    "        int(row['total_reads']) - int(row['number of reads with indels'])]\n",
    "\n",
    "        row2 = edited.iloc[index]\n",
    "        #display(row2)\n",
    "        cont['edited'] = [int(row2['number of reads with indels']),\n",
    "        int(row2['total_reads']) - int(row2['number of reads with indels'])]\n",
    "        \n",
    "        cont['type'] = ['indel', 'no indel']\n",
    "        cont.set_index('type', inplace=True)\n",
    "        \n",
    "        # display(cont)\n",
    "        #not quite significant -- perhaps because don't have enough depth\n",
    "        #now that we have constructed the contigency tables - do some stats !\n",
    "        odds_ratio, p_value = stats.fisher_exact(cont)\n",
    "        #print(odds_ratio,p_value)\n",
    "\n",
    "        \n",
    "        # #create the regions table\n",
    "        # #comp_df.loc[comp_df['REGION'] == region, 'deletion odds_ratio'] = odds_ratio\n",
    "        # comp_df.loc[comp_df['REGION'] == region, 'deletion p-value'] = p_value\n",
    "        \n",
    "        # comp_df.loc[comp_df['REGION'] == region, 'indel odds_ratio'] = odds_ratio\n",
    "\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'chrom'] = row['chrom']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'start'] = row2['start']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'end'] = row['end']\n",
    "        \n",
    "        comp_df.loc[comp_df['REGION'] == region, 'edited indel %'] = row2['% reads with an indel']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'wt indel %'] = row['% reads with an indel']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'edited indel %'] = row2['% reads with an indel']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'total edited reads'] = row2['total_reads']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'total wt reads'] = row['total_reads']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'edited reads with indels '] = row2['number of reads with indels']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'wt reads with indels'] = row['number of reads with indels']\n",
    "        comp_df.loc[comp_df['REGION'] == region, 'indel p-value'] = p_value\n",
    "        \n",
    "    return comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d0db33-3636-4019-9b50-9e112dac26a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#can do it for each replicate  - and then join on region\n",
    "comparison_tables = {'ALTC': [None, None],\n",
    "                     'ALT7': [None, None],\n",
    "                     'REX4': [None, None],\n",
    "                     'REXC': [None, None]}\n",
    "\n",
    "for condition in ['ALT7', 'REXC', 'REX4', 'ALTC']:\n",
    "    for replicate in [0,1]:\n",
    "        print('CONDITION', condition)\n",
    "        # display(control_dfs[condition])\n",
    "        # display(edited_dfs[condition][replicate])\n",
    "        display(control_dfs[condition])\n",
    "        comparison_tables[condition][replicate] = construct_comp_tbl(control_dfs[condition], edited_dfs[condition][replicate])\n",
    "        comparison_tables[condition][replicate]['trial'] = replicate\n",
    "        print('done with a condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea21b95-6df1-41f3-8bf7-f93e7a78331f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#can do it for each replicate  - and then join on region\n",
    "comparison_tables = {'ALTC': [None, None],\n",
    "                     'ALT7': [None, None],\n",
    "                     'REX4': [None, None],\n",
    "                     'REXC': [None, None]}\n",
    "\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in [0,1]:\n",
    "        print('CONDITION', condition)\n",
    "        # display(control_dfs[condition])\n",
    "        # display(edited_dfs[condition][replicate])\n",
    "        display(control_dfs[condition])\n",
    "        comparison_tables[condition][replicate] = construct_comp_tbl(control_dfs[condition], edited_dfs[condition][replicate])\n",
    "        comparison_tables[condition][replicate]['trial'] = replicate\n",
    "        print('done with a condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7e979-4b41-4beb-919c-2015a38ff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all NaNs with 0 in both DataFrames\n",
    "edited_dfs['ALTC'][0] = edited_dfs['ALTC'][0].fillna(0)\n",
    "edited_dfs['ALTC'][1] = edited_dfs['ALTC'][1].fillna(0)\n",
    "\n",
    "control_dfs['ALTC'] = control_dfs['ALTC'].fillna(0)\n",
    "\n",
    "edited_dfs['ALTC'][1][edited_dfs['ALTC'][1]['REGION'] == 'REGION_15.bam']\n",
    "edited_dfs['ALTC'][0][edited_dfs['ALTC'][0]['REGION'] == 'REGION_15.bam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ab01e-ddbb-466a-b7c7-6e26e90eaacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    for replicate in np.arange(0,2):\n",
    "        # display(edited_dfs[condition][replicate])\n",
    "        #display(comparison_tables[condition][replicate])\n",
    "        print(f\"{condition}_{replicate}casoffinder_taylor_consensus_comparison_hg38.csv\")\n",
    "        comparison_tables[condition][replicate].to_csv(f\"{condition}{replicate}casoffinder_taylor_consensus_comparison_hg38.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1be2f4-474e-407b-9d88-6ef83112562e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comparison_tables['ALTC'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d759980b-ee74-4805-a63c-6d09ec1eb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the CSVs from comparison into the dictionary (access again!)\n",
    "\n",
    "# for condition in ['ALT7', 'ALTC', 'REXC', 'REX4']:\n",
    "#     for replicate in np.arange(0,2):\n",
    "#         print('CONDITION', condition)\n",
    "#         # display(control_dfs[condition])\n",
    "#         # display(edited_dfs[condition][replicate])\n",
    "#         comparison_tables[condition][replicate] = pd.read_csv(f\"{condition}_{replicate}consensus_comparison_hg38_con_filtered.csv\")\n",
    "#         comparison_tables[condition][replicate]['trial'] = replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34726f83-b9b2-43f1-9bb7-6130f635712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(comparison_tables['ALTC'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb3091-0200-42ac-80d9-9791a7dc7ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#can do a combination - merge the dataframes together for the replicates\n",
    "#add a new row that gives the condition - so that when you join the two tables there is something that distinguishes the 2 replicates\n",
    "\n",
    "merged_comparison_tables = {'ALTC': None,\n",
    "                     'ALT7': None,\n",
    "                     'REX4': None,\n",
    "                     'REXC': None}\n",
    "\n",
    "for condition in ['ALTC', 'ALT7', 'REXC', 'REX4']:\n",
    "    print('CONDITION', condition)\n",
    "    merged_comparison_tables[condition] = pd.concat([comparison_tables[condition][0], comparison_tables[condition][1]])\n",
    "    display(merged_comparison_tables[condition][merged_comparison_tables[condition]['REGION'] == 'REGION_0.bam'])\n",
    "    print((merged_comparison_tables[condition].shape[0]))\n",
    "    display(comparison_tables[condition][0])\n",
    "    display(comparison_tables[condition][1])\n",
    "    merged_comparison_tables[condition].to_csv(f\"{condition}taylor_consensus_merged_comparisond_con_new_hg38_filtered_mp20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7faac-c23f-4b36-b240-e7808f82ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_comparison_tables['ALTC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca81da-f3cf-42d0-b9c9-506a132aeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the figure\n",
    "\n",
    "\n",
    "## chr9:27575447-27575470 (ALT7) REGION_88.bam\n",
    "\n",
    "\n",
    "# chr9:27573509-27573532 (REXC) REGION_78.bam\t\n",
    "# chr9:27575447-27575470 (ALT7) REGION_88.bam\n",
    "# chr9:27573647-27573670 (REX4) REGION_14.bam\n",
    "\n",
    "def plot_scatter(tbl):\n",
    "    plt.figure(figsize=(8,6))\n",
    "\n",
    "    # Color the first point differently by separating it\n",
    "    sns.scatterplot(\n",
    "        x=tbl[\"wt indel %\"].to_list()[1:],  # Exclude first point\n",
    "        y=tbl[\"edited indel %\"].to_list()[1:],  # Exclude first point\n",
    "        color='black',  # Makes the rest of the points black\n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "    # Plot the first point with a different color (e.g., red)\n",
    "    sns.scatterplot(\n",
    "        x=[tbl[\"wt indel %\"].to_list()[167]],  # First point\n",
    "        y=[tbl[\"edited indel %\"].to_list()[167]],  # First point\n",
    "        color='red',  # Different color for the first point\n",
    "        s=100,  # Increase size of first point\n",
    "        label=\"Edited Region (ALT7 Guide - chr9:27575447-27575470 )\"  # Optional: add label for legend\n",
    "    )\n",
    "    \n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Non-Edited Indel Percentage (%)\", fontsize=12)  # X-axis label\n",
    "    plt.ylabel(\"Edited Indel Percentage (%)\", fontsize=12)  # Y-axis label\n",
    "    plt.title(\"Indel Percentage Comparison: Non-Edited vs. Edited (Replicate 1)\", fontsize=14)  # Title\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.legend()  # Optional: to show the label in the legend\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#tbl = merged_comparison_tables['ALT7'][merged_comparison_tables['ALT7']['trial'] == 0]\n",
    "\n",
    "tbl = comparison_tables['REXC'][0]\n",
    "display(tbl)\n",
    "plot_scatter(tbl)\n",
    "\n",
    "#display(comparison_tables['REX4'][0][comparison_tables['REX4'][0]['REGION' == 'REGION_15.bam']])\n",
    "display(comparison_tables['ALT7'][1].head(15))\n",
    "\n",
    "\n",
    "#comparison_tables['ALTC'][0][comparison_tables['ALTC'][0]['chrom'] == 'chr9'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82888491-5f70-4b80-821f-fbb80a45ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_comparison_tables['REX4'][merged_comparison_tables['REX4']['REGION'] == 'REGION_14.bam']\n",
    "display(edited_dfs['REX4'][0][edited_dfs['REX4'][0]['REGION'] == 'REGION_14.bam'])\n",
    "display(control_dfs['REX4'][control_dfs['REX4']['REGION'] == 'REGION_14.bam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d710421-c273-4614-a598-f92a7353c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(edited_dfs['REXC'][0][edited_dfs['REXC'][0]['REGION'] == 'REGION_78.bam'])\n",
    "display(control_dfs['REXC'][control_dfs['REXC']['REGION'] == 'REGION_78.bam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952bfd0-45d8-4402-8090-fc5d54794201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i for i in edited_dfs['REXC'][0][edited_dfs['REXC'][0]['REGION'] == 'REGION_78.bam']['deletion lengths'].to_list()])\n",
    "print(control_dfs['REXC'][control_dfs['REXC']['REGION'] == 'REGION_78.bam']['deletion lengths'].to_list())\n",
    "\n",
    "#why are there so many 6 bp deletions??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d2cf0-7ca4-4991-b78c-756e46abe261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # To safely evaluate string representations of lists\n",
    "\n",
    "# Extract deletion lengths\n",
    "edited_raw = edited_dfs['REXC'][0][edited_dfs['REXC'][0]['REGION'] == 'REGION_78.bam']['deletion lengths'].to_list()\n",
    "control_raw = control_dfs['REXC'][control_dfs['REXC']['REGION'] == 'REGION_78.bam']['deletion lengths'].to_list()\n",
    "\n",
    "# Convert possible string representations of lists to actual lists\n",
    "if isinstance(edited_raw, str):  \n",
    "    edited_raw = ast.literal_eval(edited_raw)  \n",
    "if isinstance(control_raw, str):  \n",
    "    control_raw = ast.literal_eval(control_raw)  \n",
    "\n",
    "# Flatten the lists\n",
    "edited_deletion_lengths = [item[0] if isinstance(item, list) else item for item in edited_raw]\n",
    "control_deletion_lengths = [item[0] if isinstance(item, list) else item for item in control_raw]\n",
    "\n",
    "print(\"Edited Deletion Lengths:\", np.array(edited_deletion_lengths[0]))\n",
    "print(\"Control Deletion Lengths:\", control_deletion_lengths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667971b3-5b75-4a0a-8ed5-16b39342fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # Used to safely evaluate string representations of lists\n",
    "\n",
    "# Extract the raw data from the DataFrame\n",
    "edited_raw = edited_dfs['REXC'][0][edited_dfs['REXC'][0]['REGION'] == 'REGION_78.bam']['deletion lengths'].to_list()\n",
    "\n",
    "# If the first item is a string, convert it to a list\n",
    "if isinstance(edited_raw, list) and len(edited_raw) == 1 and isinstance(edited_raw[0], str):\n",
    "    edited_raw = ast.literal_eval(edited_raw[0])  # Convert string to a proper list\n",
    "\n",
    "# Now flatten the nested list\n",
    "edited_deletion_lengths = [x[0] for x in edited_raw]  # Extract numbers from single-item lists\n",
    "\n",
    "print(edited_deletion_lengths)  # Now it's a proper list of numbers\n",
    "\n",
    "import ast  # Used to safely evaluate string representations of lists\n",
    "\n",
    "# Extract the raw data from the DataFrame\n",
    "control_raw = control_dfs['REXC'][control_dfs['REXC']['REGION'] == 'REGION_78.bam']['deletion lengths'].to_list()\n",
    "\n",
    "# If the first item is a string, convert it to a list\n",
    "if isinstance(control_raw, list) and len(control_raw) == 1 and isinstance(control_raw[0], str):\n",
    "    control_raw = ast.literal_eval(control_raw[0])  # Convert string to a proper list\n",
    "\n",
    "# Now flatten the nested list\n",
    "control_deletion_lengths = [x[0] for x in control_raw]  # Extract numbers from single-item lists\n",
    "\n",
    "print(control_deletion_lengths)  # Now it's a proper list of numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2cb6c5-8fe8-43d2-834f-dd481187af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np  # For histogram calculations\n",
    "\n",
    "# Extract the raw data from the DataFrame for CONTROL\n",
    "control_raw = control_dfs['REX4'][control_dfs['REX4']['REGION'] == 'REGION_14.bam']['deletion lengths'].to_list()\n",
    "if isinstance(control_raw, list) and len(control_raw) == 1 and isinstance(control_raw[0], str):\n",
    "    control_raw = ast.literal_eval(control_raw[0])  # Convert string to a proper list\n",
    "control_deletion_lengths = [x[0] for x in control_raw]  # Extract numbers from single-item lists\n",
    "\n",
    "# Extract the raw data from the DataFrame for EDITED (1)\n",
    "edited_raw_1 = edited_dfs['REX4'][0][edited_dfs['REX4'][0]['REGION'] == 'REGION_14.bam']['deletion lengths'].to_list()\n",
    "if isinstance(edited_raw_1, list) and len(edited_raw_1) == 1 and isinstance(edited_raw_1[0], str):\n",
    "    edited_raw_1 = ast.literal_eval(edited_raw_1[0])  # Convert string to a proper list\n",
    "edited_deletion_lengths_1 = [x[0] for x in edited_raw_1]  # Extract numbers from single-item lists\n",
    "\n",
    "# Extract the raw data from the DataFrame for EDITED (2)\n",
    "edited_raw_2 = edited_dfs['REX4'][1][edited_dfs['REX4'][1]['REGION'] == 'REGION_14.bam']['deletion lengths'].to_list()\n",
    "if isinstance(edited_raw_2, list) and len(edited_raw_2) == 1 and isinstance(edited_raw_2[0], str):\n",
    "    edited_raw_2 = ast.literal_eval(edited_raw_2[0])  # Convert string to a proper list\n",
    "edited_deletion_lengths_2 = [x[0] for x in edited_raw_2]  # Extract numbers from single-item lists\n",
    "\n",
    "# Calculate the bin range for all data\n",
    "all_deletion_lengths = edited_deletion_lengths_1 + edited_deletion_lengths_2 + control_deletion_lengths\n",
    "bin_range = range(min(all_deletion_lengths), max(all_deletion_lengths) + 1)\n",
    "bin_width = 1  # Set the width of the bins\n",
    "\n",
    "# Compute histogram values\n",
    "control_hist, bin_edges = np.histogram(control_deletion_lengths, bins=bin_range)\n",
    "edited_hist_1, _ = np.histogram(edited_deletion_lengths_1, bins=bin_range)\n",
    "edited_hist_2, _ = np.histogram(edited_deletion_lengths_2, bins=bin_range)\n",
    "\n",
    "# Set the positions for each dataset's bars\n",
    "width = 0.3  # Bar width\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2  # Get the center of each bin for placing bars\n",
    "\n",
    "# Create the combined histogram with bars side by side\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot the bars for the control dataset\n",
    "plt.bar(bin_centers - width, control_hist, width=width, alpha=0.7, color='red', edgecolor='black', label='Control')\n",
    "\n",
    "# Plot the bars for the first edited dataset\n",
    "plt.bar(bin_centers, edited_hist_1, width=width, alpha=0.7, color='blue', edgecolor='black', label='Edited 1')\n",
    "\n",
    "# Plot the bars for the second edited dataset\n",
    "plt.bar(bin_centers + width, edited_hist_2, width=width, alpha=0.7, color='cyan', edgecolor='black', label='Edited 2')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Deletion Length (bp)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Deletion Lengths On Target Region - REX4\")\n",
    "plt.legend()  # Add legend to differentiate between datasets\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604d1cf-9c7d-44e6-a12b-cc086e598617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedc3c7-2117-4b6e-ad7b-14cddd0f79b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f56a7d-ccad-47d6-9e8d-6b50ae0e2b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
